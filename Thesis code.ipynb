{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IanJ5uxszDqc"
      },
      "outputs": [],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTmCwJ0M-qDF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import SimpleITK as sitk\n",
        "import tensorflow as tf\n",
        "from torchvision.utils import make_grid\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "from skimage.feature import hog\n",
        "from skimage.transform import resize\n",
        "from PIL import Image\n",
        "import configparser\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from google.colab import drive\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix,classification_report,roc_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score,balanced_accuracy_score,roc_auc_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import cv2\n",
        "from time import perf_counter\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i1P_SiDaIGD"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.images[index]\n",
        "        y = self.labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            x = Image.fromarray(self.images[index].astype(np.uint8).transpose(1, 2, 0))\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(to_device(batch,device)) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def model_checkpoint(filename,model):\n",
        "    torch.save(model.state_dict(), filename)\n",
        "\n",
        "def save_checkpoint(epoch,model,optimizer):\n",
        "    checkpoint = {\n",
        "    'epoch': epoch + 1,\n",
        "    'state_dict': model.state_dict(),\n",
        "    'optimizer': optimizer.state_dict()\n",
        "    }\n",
        "    return 0\n",
        "\n",
        "def load_checkpoint(checkpoint_fpath, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    return model, optimizer, checkpoint['epoch']\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader,filename,patient_epochs,restore_best_weights=True,opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    es=EarlyStopping()\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "        model_checkpoint(filename,model)\n",
        "        stop=early_stopping(model,history,patient_epochs,es,restore_best_weights,filename)\n",
        "        if stop == True :\n",
        "           print(f\"Early stopping at epoch {epoch}\")\n",
        "           continue\n",
        "    return history\n",
        "\n",
        "\n",
        "def early_stopping(model,history,patient_epochs,es,restore_best_weights,filename):\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    size = len(val_losses)\n",
        "    last_loss=val_losses[size-1]\n",
        "    threshold=0\n",
        "    if es.get_best_loss() >= last_loss:\n",
        "             es.set_best_loss(last_loss)\n",
        "             es.set_best_model(model)\n",
        "    if size > 1 :\n",
        "          last_but_one_loss=val_losses[size-2]\n",
        "          if last_loss-last_but_one_loss > threshold :\n",
        "             es.increase_counter()\n",
        "          else :\n",
        "             es.null_counter()\n",
        "    if es.get_counter() >= patient_epochs:\n",
        "       if restore_best_weights == True :\n",
        "              model_checkpoint(es.get_best_model(),filename)\n",
        "       return True\n",
        "    print(f\"Early stopping counter is {es.get_counter()}\")\n",
        "    return False\n",
        "\n",
        "class EarlyStopping():\n",
        "    def __init__(self):\n",
        "      self.counter=0\n",
        "      self.best_loss=1\n",
        "      self.best_model=float(\"nan\")\n",
        "\n",
        "    def increase_counter(self):\n",
        "      self.counter+=1\n",
        "\n",
        "    def get_counter(self):\n",
        "      return self.counter\n",
        "\n",
        "    def null_counter(self):\n",
        "      self.counter=0\n",
        "\n",
        "    def get_best_loss(self):\n",
        "      return self.best_loss\n",
        "\n",
        "    def set_best_loss(self,best_loss):\n",
        "       self.best_loss=best_loss\n",
        "\n",
        "    def set_best_model(self,best_model):\n",
        "       self.best_model=best_model\n",
        "\n",
        "    def get_best_model(self):\n",
        "       return self.best_model\n",
        "\n",
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs')\n",
        "\n",
        "\n",
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "def predict_image(img, model):\n",
        "    dataset=[]\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return preds[0].item()\n",
        "\n",
        "def predict_image_softmax(img,model):\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    yb = model(xb)\n",
        "    yb_softmax=torch.softmax(yb,dim=1)\n",
        "    tensor, preds  = torch.max(yb_softmax, dim=1)\n",
        "    return tensor[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNRiE8NU3Wos"
      },
      "outputs": [],
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = to_device(batch,device)\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = to_device(batch,device)\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
        "\n",
        "\n",
        "class ClassificationModel(ImageClassificationBase):\n",
        "    def __init__(self,num_classes=2):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer10 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer11 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer12 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer13 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(7*7*512, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.layer8(out)\n",
        "        out = self.layer9(out)\n",
        "        out = self.layer10(out)\n",
        "        out = self.layer11(out)\n",
        "        out = self.layer12(out)\n",
        "        out = self.layer13(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXoG_nLhfALD"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "\n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "\n",
        "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "\n",
        "        #downsample if needed\n",
        "        if self.i_downsample is not None:\n",
        "            identity = self.i_downsample(identity)\n",
        "        #add identity\n",
        "        x+=identity\n",
        "        x=self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      identity = x.clone()\n",
        "\n",
        "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
        "      x = self.batch_norm2(self.conv2(x))\n",
        "\n",
        "      if self.i_downsample is not None:\n",
        "          identity = self.i_downsample(identity)\n",
        "      print(x.shape)\n",
        "      print(identity.shape)\n",
        "      x += identity\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "class ResNet(ImageClassificationBase):\n",
        "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
        "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
        "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
        "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
        "        ii_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
        "            ii_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
        "            )\n",
        "\n",
        "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
        "        self.in_channels = planes*ResBlock.expansion\n",
        "\n",
        "        for i in range(blocks-1):\n",
        "            layers.append(ResBlock(self.in_channels, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVumq-vuWyNu"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import OrderedDict\n",
        "from functools import partial\n",
        "from typing import Any, List, Optional, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as cp\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self, num_input_features: int, growth_rate: int, bn_size: int, drop_rate: float, memory_efficient: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.BatchNorm2d(num_input_features)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(num_input_features, bn_size * growth_rate, kernel_size=1, stride=1, bias=False)\n",
        "\n",
        "        self.norm2 = nn.BatchNorm2d(bn_size * growth_rate)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(bn_size * growth_rate, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.drop_rate = float(drop_rate)\n",
        "        self.memory_efficient = memory_efficient\n",
        "\n",
        "    def bn_function(self, inputs: List[Tensor]) -> Tensor:\n",
        "        concated_features = torch.cat(inputs, 1)\n",
        "        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\n",
        "        return bottleneck_output\n",
        "\n",
        "    # todo: rewrite when torchscript supports any\n",
        "    def any_requires_grad(self, input: List[Tensor]) -> bool:\n",
        "        for tensor in input:\n",
        "            if tensor.requires_grad:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    @torch.jit.unused  # noqa: T484\n",
        "    def call_checkpoint_bottleneck(self, input: List[Tensor]) -> Tensor:\n",
        "        def closure(*inputs):\n",
        "            return self.bn_function(inputs)\n",
        "\n",
        "        return cp.checkpoint(closure, *input)\n",
        "\n",
        "    @torch.jit._overload_method  # noqa: F811\n",
        "    def forward(self, input: List[Tensor]) -> Tensor:  # noqa: F811\n",
        "        pass\n",
        "\n",
        "    @torch.jit._overload_method  # noqa: F811\n",
        "    def forward(self, input: Tensor) -> Tensor:  # noqa: F811\n",
        "        pass\n",
        "\n",
        "    # torchscript does not yet support *args, so we overload method\n",
        "    # allowing it to take either a List[Tensor] or single Tensor\n",
        "    def forward(self, input: Tensor) -> Tensor:  # noqa: F811\n",
        "        if isinstance(input, Tensor):\n",
        "            prev_features = [input]\n",
        "        else:\n",
        "            prev_features = input\n",
        "\n",
        "        if self.memory_efficient and self.any_requires_grad(prev_features):\n",
        "            if torch.jit.is_scripting():\n",
        "                raise Exception(\"Memory Efficient not supported in JIT\")\n",
        "\n",
        "            bottleneck_output = self.call_checkpoint_bottleneck(prev_features)\n",
        "        else:\n",
        "            bottleneck_output = self.bn_function(prev_features)\n",
        "\n",
        "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return new_features\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.ModuleDict):\n",
        "    _version = 2\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers: int,\n",
        "        num_input_features: int,\n",
        "        bn_size: int,\n",
        "        growth_rate: int,\n",
        "        drop_rate: float,\n",
        "        memory_efficient: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(\n",
        "                num_input_features + i * growth_rate,\n",
        "                growth_rate=growth_rate,\n",
        "                bn_size=bn_size,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient,\n",
        "            )\n",
        "            self.add_module(\"denselayer%d\" % (i + 1), layer)\n",
        "\n",
        "    def forward(self, init_features: Tensor) -> Tensor:\n",
        "        features = [init_features]\n",
        "        for name, layer in self.items():\n",
        "            new_features = layer(features)\n",
        "            features.append(new_features)\n",
        "        return torch.cat(features, 1)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features: int, num_output_features: int) -> None:\n",
        "        super().__init__()\n",
        "        self.norm = nn.BatchNorm2d(num_input_features)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv = nn.Conv2d(num_input_features, num_output_features, kernel_size=1, stride=1, bias=False)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "class DenseNet121(ImageClassificationBase):\n",
        "    def __init__(\n",
        "        self,\n",
        "        growth_rate: int = 32,\n",
        "        block_config: Tuple[int, int, int, int] = (6, 12, 24, 16),\n",
        "        num_init_features: int = 64,\n",
        "        bn_size: int = 4,\n",
        "        drop_rate: float = 0,\n",
        "        num_classes: int = 2,\n",
        "        memory_efficient: bool = False,\n",
        "    ) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\"conv0\", nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "                    (\"norm0\", nn.BatchNorm2d(num_init_features)),\n",
        "                    (\"relu0\", nn.ReLU(inplace=True)),\n",
        "                    (\"pool0\", nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(\n",
        "                num_layers=num_layers,\n",
        "                num_input_features=num_features,\n",
        "                bn_size=bn_size,\n",
        "                growth_rate=growth_rate,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient,\n",
        "            )\n",
        "            self.features.add_module(\"denseblock%d\" % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module(\"transition%d\" % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module(\"norm5\", nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "def _densenet(\n",
        "    growth_rate: int,\n",
        "    block_config: Tuple[int, int, int, int],\n",
        "    num_init_features: int,\n",
        "    progress: bool,\n",
        "    **kwargs: Any,\n",
        ") -> DenseNet121:\n",
        "    return  model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TOSQaQUJ7ea"
      },
      "outputs": [],
      "source": [
        "class Convolutional_Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ### encoder\n",
        "        self.conv1 = nn.Conv2d(3,64,5)\n",
        "        self.maxpool = nn.MaxPool2d(2,return_indices=True)\n",
        "        self.conv2 = nn.Conv2d(64,64,5)\n",
        "        self.conv3 = nn.Conv2d(64,128,5)\n",
        "        ### decoder\n",
        "        self.deconv1 = nn.ConvTranspose2d(128,64,5)\n",
        "        self.unpool = nn.MaxUnpool2d(2)\n",
        "        self.deconv2 = nn.ConvTranspose2d(64,64,5)\n",
        "        self.deconv3 = nn.ConvTranspose2d(64,3,5)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x,ind1 = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x,ind2 = self.maxpool(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.deconv1(x)\n",
        "        x = self.unpool(x,ind2)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.unpool(x,ind1)\n",
        "        x = self.deconv3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSRRgCsF7e6Z"
      },
      "outputs": [],
      "source": [
        "device=get_default_device()\n",
        "nb_frames_4ch_list=[]\n",
        "nb_frames_2ch_list=[]\n",
        "ages_list=[]\n",
        "sex_list=[]\n",
        "image_quality_4ch_list=[]\n",
        "image_quality_2ch_list=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CU490B9WjUA"
      },
      "outputs": [],
      "source": [
        "for i in range(1,451):\n",
        "    if i<10:\n",
        "         file_name_4ch= 'drive/MyDrive/training_dataset/training/patient000'+str(i)+'/Info_4CH.cfg'\n",
        "         file_name_2ch= 'drive/MyDrive/training_dataset/training/patient000' +str(i) +'/Info_2CH.cfg'\n",
        "    elif i<100 :\n",
        "         file_name_4ch= 'drive/MyDrive/training_dataset/training/patient00'+str(i)+'/Info_4CH.cfg'\n",
        "         file_name_2ch= 'drive/MyDrive/training_dataset/training/patient00' +str(i) +'/Info_2CH.cfg'\n",
        "    else :\n",
        "         file_name_4ch= 'drive/MyDrive/training_dataset/training/patient0'+str(i)+'/Info_4CH.cfg'\n",
        "         file_name_2ch= 'drive/MyDrive/training_dataset/training/patient0' +str(i) +'/Info_2CH.cfg'\n",
        "    with open(file_name_4ch) as f:\n",
        "        file_content = '[dummy_section]\\n' + f.read()\n",
        "    config_parser =configparser.RawConfigParser()\n",
        "    config_parser.read_string(file_content)\n",
        "    ages_list.append(int(config_parser['dummy_section']['Age']))\n",
        "    sex_list.append(config_parser['dummy_section']['Sex'])\n",
        "    nb_frames_4ch_list.append(int(config_parser['dummy_section']['NbFrame']))\n",
        "    image_quality_4ch_list.append(config_parser['dummy_section']['ImageQuality'])\n",
        "    with open(file_name_2ch) as f:\n",
        "        file_content = '[dummy_section]\\n' + f.read()\n",
        "    config_parser =configparser.RawConfigParser()\n",
        "    config_parser.read_string(file_content)\n",
        "    nb_frames_2ch_list.append(int(config_parser['dummy_section']['NbFrame']))\n",
        "    image_quality_2ch_list.append(config_parser['dummy_section']['ImageQuality'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfty1W1Q9Z21"
      },
      "outputs": [],
      "source": [
        "dataframe=pd.DataFrame({'Age':ages_list,'Sex':sex_list,'Image_quality_4ch':image_quality_4ch_list,'Nb_frames_4ch':nb_frames_4ch_list,'Image_quality_2ch':image_quality_2ch_list,'Nb_frames_2ch':nb_frames_2ch_list})\n",
        "dataframe['patient']=range(1,451)\n",
        "print(dataframe)\n",
        "print(\"Total 4ch examples\")\n",
        "size=len(dataframe)\n",
        "print(dataframe['Nb_frames_4ch'].sum())\n",
        "print(\"Total 2ch examples\")\n",
        "print(dataframe['Nb_frames_2ch'].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jns50B3Fr9NC"
      },
      "outputs": [],
      "source": [
        "print(dataframe['Image_quality_4ch'].value_counts())\n",
        "print(dataframe['Image_quality_2ch'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fx0D7uUHGzF"
      },
      "outputs": [],
      "source": [
        "print(dataframe['Sex'].value_counts())\n",
        "print(dataframe[\"Nb_frames_4ch\"].loc[dataframe[\"Image_quality_4ch\"] == \"Poor\" ].sum())\n",
        "print(dataframe[\"Nb_frames_4ch\"].loc[dataframe[\"Image_quality_4ch\"] == \"Medium\" ].sum())\n",
        "print(dataframe[\"Nb_frames_4ch\"].loc[dataframe[\"Image_quality_4ch\"] == \"Good\" ].sum())\n",
        "print(dataframe[\"Nb_frames_2ch\"].loc[dataframe[\"Image_quality_2ch\"] == \"Poor\" ].sum())\n",
        "print(dataframe[\"Nb_frames_2ch\"].loc[dataframe[\"Image_quality_2ch\"] == \"Medium\" ].sum())\n",
        "print(dataframe[\"Nb_frames_2ch\"].loc[dataframe[\"Image_quality_2ch\"] == \"Good\" ].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEE6JN6WU8Su"
      },
      "outputs": [],
      "source": [
        "colors=['red','black']\n",
        "#sns.countplot(dataframe['Sex'],palette=colors)\n",
        "fig,ax1= plt.subplots(ncols=1, figsize=(10, 5))\n",
        "dataframe.groupby('Sex').size().plot(kind='pie', autopct='%.2f')\n",
        "ax1.set_ylabel('Sex', size=22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtQSBBT8Iwj0"
      },
      "outputs": [],
      "source": [
        "Y=np.zeros(len(dataframe))\n",
        "X_train_dataframe,Val_set_dataframe,Y_train,Y_test=train_test_split(dataframe, Y, test_size=0.2,stratify=dataframe['Image_quality_4ch'],random_state=42)\n",
        "print(X_train_dataframe.shape)\n",
        "print(Val_set_dataframe.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb9oePSJw72K"
      },
      "outputs": [],
      "source": [
        "print(X_train_dataframe)\n",
        "print(Val_set_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLu_7GTNpWK-"
      },
      "outputs": [],
      "source": [
        "dataframe=X_train_dataframe\n",
        "print(dataframe['Image_quality_4ch'].value_counts())\n",
        "print(dataframe['Image_quality_2ch'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GQheAu-pWVA"
      },
      "outputs": [],
      "source": [
        "print(dataframe['Sex'].value_counts())\n",
        "print(dataframe[\"Nb_frames_4ch\"].loc[dataframe[\"Image_quality_4ch\"] == \"Poor\" ].sum())\n",
        "print(dataframe[\"Nb_frames_4ch\"].loc[dataframe[\"Image_quality_4ch\"] == \"Medium\" ].sum())\n",
        "print(dataframe[\"Nb_frames_4ch\"].loc[dataframe[\"Image_quality_4ch\"] == \"Good\" ].sum())\n",
        "print(dataframe[\"Nb_frames_2ch\"].loc[dataframe[\"Image_quality_2ch\"] == \"Poor\" ].sum())\n",
        "print(dataframe[\"Nb_frames_2ch\"].loc[dataframe[\"Image_quality_2ch\"] == \"Medium\" ].sum())\n",
        "print(dataframe[\"Nb_frames_2ch\"].loc[dataframe[\"Image_quality_2ch\"] == \"Good\" ].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyLlkfDKYwH_"
      },
      "outputs": [],
      "source": [
        "preprocessing = torchvision.transforms.Compose([\n",
        "   torchvision.transforms.ToPILImage(),\n",
        "   torchvision.transforms.Resize((224,224)),\n",
        "   torchvision.transforms.ToTensor(),\n",
        "   torchvision.transforms.Normalize(mean=[0], std=[1])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE_zWbmEIqUV"
      },
      "outputs": [],
      "source": [
        "image_file_path=\"drive/MyDrive/training_dataset/training/patient0002/patient0002_4CH_sequence.mhd\"\n",
        "img = sitk.ReadImage(image_file_path)\n",
        "img_4=sitk.GetArrayFromImage(img)\n",
        "plt.imshow(img_4[0,:,:], cmap='gray')\n",
        "print(img_4.shape)\n",
        "#rgb_image = cv2.cvtColor(img_4[0,:,:],cv2.COLOR_GRAY2RGB)\n",
        "#print(rgb_image.shape)\n",
        "#plt.imshow(rgb_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ut40-kwx3Nkd"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "image_file_path=\"drive/MyDrive/training_dataset/training/patient0001/patient0001_2CH_sequence.mhd\"\n",
        "img = sitk.ReadImage(image_file_path)\n",
        "img_4=sitk.GetArrayFromImage(img)\n",
        "fig = plt.figure(figsize=(16., 16.))\n",
        "grid = ImageGrid(fig, 111,\n",
        "                 nrows_ncols=(1,3),\n",
        "                 axes_pad=0.1,\n",
        "                 )\n",
        "for ax, im in zip(grid,img_4):\n",
        "    ax.imshow(im,cmap=\"gray\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUEjM7HoFYOt"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "img_4=[]\n",
        "image_file_path=\"drive/MyDrive/training_dataset/training/patient0001/patient0001_2CH_sequence.mhd\"\n",
        "img = sitk.ReadImage(image_file_path)\n",
        "img_1=sitk.GetArrayFromImage(img)\n",
        "img_4.append(img_1)\n",
        "image_file_path=\"drive/MyDrive/training_dataset/training/patient0001/patient0001_2CH_sequence.mhd\"\n",
        "img = sitk.ReadImage(image_file_path)\n",
        "img_1=sitk.GetArrayFromImage(img)\n",
        "img_4.append(img_1)\n",
        "image_file_path=\"drive/MyDrive/training_dataset/training/patient0001/patient0001_2CH_sequence.mhd\"\n",
        "img = sitk.ReadImage(image_file_path)\n",
        "img_1=sitk.GetArrayFromImage(img)\n",
        "img_4.append(img_1)\n",
        "\n",
        "fig = plt.figure(figsize=(16., 16.))\n",
        "grid = ImageGrid(fig, 111,\n",
        "                 nrows_ncols=(1,3),\n",
        "                 axes_pad=0.1,\n",
        "                 )\n",
        "for ax, im in zip(grid,img_4):\n",
        "    ax.imshow(im,cmap=\"gray\")\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2q5NXUrmX2U"
      },
      "outputs": [],
      "source": [
        "def scale_to_01_range(x):\n",
        "    value_range = (np.max(x) - np.min(x))\n",
        "    starts_from_zero = x - np.min(x)\n",
        "    return starts_from_zero / value_range\n",
        "\n",
        "def tsne_plot(X,Y):\n",
        "    tsne = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=30,n_iter=1000).fit_transform(X)\n",
        "    tx = tsne[:, 0]\n",
        "    ty = tsne[:, 1]\n",
        "    tx = scale_to_01_range(tx)\n",
        "    ty = scale_to_01_range(ty)\n",
        "    df = pd.DataFrame()\n",
        "    df[\"y\"] = Y\n",
        "    df[\"comp-1\"] = tx\n",
        "    df[\"comp-2\"] = ty\n",
        "    sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                palette=sns.color_palette(\"hls\", 2),\n",
        "                data=df).set(title=\"View options data T-SNE projection\")\n",
        "\n",
        "\n",
        "X,Y=create_hog_dataset_test(patients=51)\n",
        "tsne_plot(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSY5JSLdFGN9"
      },
      "outputs": [],
      "source": [
        "print(features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRqt-XlJl9YO"
      },
      "outputs": [],
      "source": [
        "def fetch_file(patient,option):\n",
        "      if patient >= 100 :\n",
        "          image_path_4ch = \"drive/MyDrive/training_dataset/training/patient0\"+str(patient)+\"/patient0\"+str(patient)+\"_4CH_sequence.mhd\"\n",
        "          image_path_2ch = \"drive/MyDrive/training_dataset/training/patient0\"+str(patient)+\"/patient0\"+str(patient)+\"_2CH_sequence.mhd\"\n",
        "      elif patient >= 10 :\n",
        "          image_path_4ch = \"drive/MyDrive/training_dataset/training/patient00\"+str(patient)+\"/patient00\"+str(patient)+\"_4CH_sequence.mhd\"\n",
        "          image_path_2ch = \"drive/MyDrive/training_dataset/training/patient00\"+str(patient)+\"/patient00\"+str(patient)+\"_2CH_sequence.mhd\"\n",
        "      else:\n",
        "          image_path_4ch = \"drive/MyDrive/training_dataset/training/patient000\"+str(patient)+\"/patient000\"+str(patient)+\"_4CH_sequence.mhd\"\n",
        "          image_path_2ch = \"drive/MyDrive/training_dataset/training/patient000\"+str(patient)+\"/patient000\"+str(patient)+\"_2CH_sequence.mhd\"\n",
        "      if option=='4CH' :\n",
        "         image_path=image_path_4ch\n",
        "      else :\n",
        "         image_path=image_path_2ch\n",
        "      return image_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_ruXP4grg64"
      },
      "outputs": [],
      "source": [
        "def get_array(image_path) :\n",
        "   img = sitk.ReadImage(image_path)\n",
        "   array = sitk.GetArrayFromImage(img)\n",
        "   return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3iMckp6YFoV"
      },
      "outputs": [],
      "source": [
        "def get_image_quality_label(image_quality):\n",
        "  if image_quality == 'Good' :\n",
        "     label=0\n",
        "  elif image_quality == 'Medium' :\n",
        "     label=1\n",
        "  else :\n",
        "     label=2\n",
        "  return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QryipD3yiiEQ"
      },
      "outputs": [],
      "source": [
        "def create_tensor_set(data_set):\n",
        "    dataset=list()\n",
        "    dataset_labels=list()\n",
        "    for i in range(len(data_set)):\n",
        "      patient=data_set['patient'].iloc[i]\n",
        "      image_4ch_file=fetch_file(patient=patient,option='4CH')\n",
        "      image_2ch_file=fetch_file(patient=patient,option='2CH')\n",
        "      image_4ch=get_array(image_4ch_file)\n",
        "      image_2ch=get_array(image_2ch_file)\n",
        "      for j in range(image_4ch.shape[0]):\n",
        "             rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             tensor_image=preprocessing(rgb_image)\n",
        "             dataset.append(tensor_image)\n",
        "             dataset_labels.append(0)\n",
        "      for j in range(image_2ch.shape[0]):\n",
        "             rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             tensor_image=preprocessing(rgb_image)\n",
        "             dataset.append(tensor_image)\n",
        "             dataset_labels.append(1)\n",
        "    return dataset,dataset_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTW8Fm3RW60z"
      },
      "outputs": [],
      "source": [
        "def create_tensor_set_test_quality():\n",
        "    dataset=list()\n",
        "    dataset_labels=list()\n",
        "    for patient in range(1,51):\n",
        "      image_4ch_file=fetch_test_file(patient=patient,option='4CH')\n",
        "      #image_2ch_file=fetch_test_file(patient=patient,option='2CH')\n",
        "      image_4ch=get_array(image_4ch_file)\n",
        "      #image_2ch=get_array(image_2ch_file)\n",
        "      quality_label_4ch=fetch_test_image_quality(patient=patient,option=\"4CH\")\n",
        "      #quality_label_2ch=fetch_test_image_quality(patient=patient,option=\"2CH\")\n",
        "      label_4ch=get_image_quality_label(quality_label_4ch)\n",
        "      #label_2ch=get_image_quality_label(quality_label_2ch)\n",
        "      for j in range(image_4ch.shape[0]):\n",
        "             rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             tensor_image=preprocessing(rgb_image)\n",
        "             dataset.append(tensor_image)\n",
        "             dataset_labels.append(label_4ch)\n",
        "      #for j in range(image_2ch.shape[0]):\n",
        "             #rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             #tensor_image=preprocessing(rgb_image)\n",
        "             #dataset.append(tensor_image)\n",
        "             #dataset_labels.append(label_2ch)\n",
        "    return dataset,dataset_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zscSSX05dqVV"
      },
      "outputs": [],
      "source": [
        "def torch_sampler(images,labels):\n",
        "   dataset=list()\n",
        "   index_list=range(len(images))\n",
        "   index_list,labels=sampling_strategy(np.array(index_list).reshape(-1,1),labels)\n",
        "   index_list=np.ravel(index_list).tolist()\n",
        "   for index in index_list:\n",
        "     dataset.append(images[index])\n",
        "   print(len(dataset))\n",
        "   return dataset,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MyCjFUhruF0S"
      },
      "outputs": [],
      "source": [
        "device=get_default_device()\n",
        "images,labels=create_tensor_set_quality(X_train_dataframe)\n",
        "print(len(images))\n",
        "#images,labels=torch_sampler(images,labels)\n",
        "train_ds=MyDataset(images=images,labels=labels)\n",
        "images,labels=create_tensor_set_quality(Val_set_dataframe)\n",
        "val_ds=MyDataset(images=images,labels=labels)\n",
        "#images,labels=create_tensor_set_quality(X_test_dataframe)\n",
        "#test_ds=MyDataset(images=images,labels=labels)\n",
        "batch_size=16\n",
        "train_loader = DataLoader(train_ds, batch_size,shuffle=True,num_workers=4, pin_memory=False)\n",
        "val_loader = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=False)\n",
        "#test_loader = DataLoader(test_ds, batch_size*2, num_workers=2, pin_memory=False)\n",
        "#train_dl = DeviceDataLoader(train_loader, device)\n",
        "#val_dl = DeviceDataLoader(val_loader, device)\n",
        "#test_dl = DeviceDataLoader(test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ_xmn1HYKa4"
      },
      "outputs": [],
      "source": [
        "device=get_default_device()\n",
        "images,labels=create_tensor_set(X_train_dataframe)\n",
        "train_ds=MyDataset(images=images,labels=labels)\n",
        "images,labels=create_tensor_set(Val_set_dataframe)\n",
        "val_ds=MyDataset(images=images,labels=labels)\n",
        "#images,labels=create_tensor_set(X_test_dataframe)\n",
        "#test_ds=MyDataset(images=images,labels=labels)\n",
        "batch_size=32\n",
        "train_loader = DataLoader(train_ds, batch_size,shuffle=True,num_workers=4, pin_memory=False)\n",
        "val_loader = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=False)\n",
        "#test_loader = DataLoader(test_ds, batch_size*2, num_workers=2, pin_memory=False)\n",
        "#train_dl = DeviceDataLoader(train_loader, device)\n",
        "#val_dl = DeviceDataLoader(val_loader, device)\n",
        "#test_dl = DeviceDataLoader(test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYlvCAu4pCMN"
      },
      "outputs": [],
      "source": [
        "images,labels=create_tensor_set(Val_set_dataframe)\n",
        "val_ds=MyDataset(images=images,labels=labels)\n",
        "batch_size=16\n",
        "val_loader = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCg2NJTspiKr",
        "outputId": "24c3b31f-4c49-4bcb-fa8b-bfe532ec208c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'val_loss': 0.07404372096061707, 'val_acc': 0.9783878326416016}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filename='drive/MyDrive/training_dataset/resnet152_450_0.001_best.pt'\n",
        "model=load_model_resnet152(filename)\n",
        "evaluate(model,val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj6BwtXPnqE9"
      },
      "outputs": [],
      "source": [
        "def video_level_classification(patient,model):\n",
        "  image_4ch_file=fetch_test_file(patient=patient,option='4CH')\n",
        "  image_2ch_file=fetch_test_file(patient=patient,option='2CH')\n",
        "  image_4ch=get_array(image_4ch_file)\n",
        "  image_2ch=get_array(image_2ch_file)\n",
        "  correct_4ch=0\n",
        "  correct_2ch=0\n",
        "  for j in range(image_4ch.shape[0]):\n",
        "             rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             tensor_image = preprocessing(rgb_image)\n",
        "             prediction = predict_image(tensor_image,model)\n",
        "             if prediction == 1 :\n",
        "               correct_4ch = correct_4ch + 1\n",
        "  for j in range(image_2ch.shape[0]):\n",
        "             rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             tensor_image=preprocessing(rgb_image)\n",
        "             prediction = predict_image(tensor_image,model)\n",
        "             if prediction == 1 :\n",
        "               correct_2ch = correct_2ch + 1\n",
        "  return correct_4ch/image_4ch.shape[0],correct_2ch/image_2ch.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Na1Uw7Z-V_IG"
      },
      "outputs": [],
      "source": [
        "filename='drive/MyDrive/training_dataset/densenet121_450_0.001_best.pt'\n",
        "model=load_model_densenet(filename)\n",
        "patients_4ch=list()\n",
        "patients_2ch=list()\n",
        "for patient in range(1,51):\n",
        "    video_4ch,video_2ch=video_level_classification(patient=patient,model=model)\n",
        "    patients_4ch.append(video_4ch)\n",
        "    patients_2ch.append(video_2ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQp-0gXfNAVy"
      },
      "outputs": [],
      "source": [
        "print(patients_4ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ujUnA6kZWaBA"
      },
      "outputs": [],
      "source": [
        "patient_4ch = pd.Series(patients_4ch)\n",
        "\n",
        "patient_4ch.plot.hist(grid=True, bins=30, rwidth=0.9,\n",
        "                   color='#607c8e')\n",
        "plt.title('Video Success precentages for 4ch Chamber view')\n",
        "plt.xlabel('Percentage of Correct Classification')\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.grid(axis='y', alpha=0.75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B5cf4FYIWaTh"
      },
      "outputs": [],
      "source": [
        "patient_2ch = pd.Series(patients_2ch)\n",
        "\n",
        "patient_2ch.plot.hist(grid=True, bins=30, rwidth=0.9,\n",
        "                   color='#607c8e')\n",
        "plt.title('Video Success precentages for 2ch Chamber view')\n",
        "plt.xlabel('Percentage of Correct Classification')\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.grid(axis='y', alpha=0.75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajF2fQ6wUaFw"
      },
      "outputs": [],
      "source": [
        "def get_view_label(view_option):\n",
        "  if view_option == '4CH':\n",
        "    return 0\n",
        "  return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4Grs_kSSALl"
      },
      "outputs": [],
      "source": [
        "def create_quality_testing(quality_option,view_option):\n",
        "  images=list()\n",
        "  labels=list()\n",
        "  label=get_view_label(view_option)\n",
        "  for patient in range(1,51):\n",
        "    image_quality=fetch_test_image_quality(patient=patient,option=view_option)\n",
        "    if image_quality != quality_option:\n",
        "       continue\n",
        "    image_file=fetch_test_file(patient=patient,option=view_option)\n",
        "    image=get_array(image_file)\n",
        "    for j in range(image.shape[0]):\n",
        "        rgb_image = cv2.cvtColor(image[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        tensor_image=preprocessing(rgb_image)\n",
        "        images.append(tensor_image)\n",
        "        labels.append(label)\n",
        "  print(len(images))\n",
        "  return images,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4PUJsDDTH6w"
      },
      "outputs": [],
      "source": [
        "device=get_default_device()\n",
        "images,labels=create_tensor_set_test_quality()\n",
        "quality_ds=MyDataset(images=images,labels=labels)\n",
        "batch_size=16\n",
        "quality_loader = DataLoader(quality_ds, batch_size*2, num_workers=2, pin_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeSB6eMuqnNP"
      },
      "outputs": [],
      "source": [
        "filename='drive/MyDrive/training_dataset/resnet152_quality_0.001.pt'\n",
        "model=load_model_resnet152(filename)\n",
        "print_perfomance_metrics(model,quality_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEHIduF75kbF"
      },
      "outputs": [],
      "source": [
        "filename='drive/MyDrive/training_dataset/densenet121_450_0.001_best.pt'\n",
        "model=load_model_densenet(filename)\n",
        "print_perfomance_metrics(model,poor_4ch_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmapfhU70Wtc"
      },
      "outputs": [],
      "source": [
        "filename='drive/MyDrive/training_dataset/densenet121_450_0.001_best.pt'\n",
        "model=load_model_densenet(filename)\n",
        "device=get_default_device()\n",
        "images,labels=create_tensor_test_set()\n",
        "test_ds=MyDataset(images=images,labels=labels)\n",
        "batch_size=32\n",
        "test_loader = DataLoader(test_ds, batch_size*2, num_workers=2, pin_memory=False)\n",
        "print_perfomance_metrics(model,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP_XIHKZi8ng"
      },
      "outputs": [],
      "source": [
        "def create_tensor_test_set():\n",
        "    dataset=list()\n",
        "    dataset_labels=list()\n",
        "    for patient in range(1,51):\n",
        "      image_4ch_file=fetch_test_file(patient=patient,option='4CH')\n",
        "      image_2ch_file=fetch_test_file(patient=patient,option='2CH')\n",
        "      image_4ch=get_array(image_4ch_file)\n",
        "      image_2ch=get_array(image_2ch_file)\n",
        "      for j in range(image_4ch.shape[0]):\n",
        "             rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             tensor_image=preprocessing(rgb_image)\n",
        "             dataset.append(tensor_image)\n",
        "             dataset_labels.append(0)\n",
        "      for j in range(image_2ch.shape[0]):\n",
        "             rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             tensor_image=preprocessing(rgb_image)\n",
        "             dataset.append(tensor_image)\n",
        "             dataset_labels.append(1)\n",
        "    return dataset,dataset_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM20eEkpitef"
      },
      "outputs": [],
      "source": [
        "device=get_default_device()\n",
        "images,labels=create_tensor_test_set()\n",
        "test_ds=MyDataset(images=images,labels=labels)\n",
        "batch_size=16\n",
        "test_loader = DataLoader(test_ds, batch_size*2, num_workers=2, pin_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POi4pUbZu1RB"
      },
      "outputs": [],
      "source": [
        "def print_perfomance_metrics(model,test_loader):\n",
        "   Y_true=np.array([])\n",
        "   Y_pred=np.array([])\n",
        "   for batch in test_loader:\n",
        "      images, labels = to_device(batch,device)\n",
        "      outputs=model(images)\n",
        "      _, pred_labels = torch.max(outputs, dim=1)\n",
        "      Y_true=np.append(Y_true,labels.cpu().numpy())\n",
        "      Y_pred=np.append(Y_pred,pred_labels.cpu().numpy())\n",
        "   labels=['Good','Medium','Poor']\n",
        "   print(classification_report(Y_true, Y_pred, target_names=labels))\n",
        "   print(confusion_matrix(Y_true, Y_pred))\n",
        "   #print(accuracy_score(Y_true,Y_pred))\n",
        "   print(balanced_accuracy_score(Y_true,Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jToFPVbzVvQP"
      },
      "outputs": [],
      "source": [
        "filename='drive/MyDrive/training_dataset/resnet152_450_0.001_best.pt'\n",
        "model=load_model_resnet152(filename)\n",
        "print_perfomance_metrics(model,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQql7BhtwmbO"
      },
      "outputs": [],
      "source": [
        "device=get_default_device()\n",
        "#video_level_classification(patient=2,model=ClassificationModel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aUEiIpR0UDE"
      },
      "outputs": [],
      "source": [
        "start_time=perf_counter()\n",
        "my_model=ClassificationModel()\n",
        "model = to_device(my_model, device)\n",
        "num_epochs = 20\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001\n",
        "filename=\"drive/MyDrive/training_dataset/vgg16_quality_0.001.pt\"\n",
        "patient_epochs=6\n",
        "history = fit(num_epochs, lr, model, train_loader, val_loader,filename,patient_epochs,restore_best_weights=True,opt_func=opt_func)\n",
        "end_time=perf_counter()\n",
        "print(f\"Elapsed time during the whole program in seconds: {end_time-start_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6pd0jCvgCfO"
      },
      "outputs": [],
      "source": [
        "start_time=perf_counter()\n",
        "my_model=ResNet(Bottleneck, [3,8,36,3], num_classes=3, num_channels=3)\n",
        "model = to_device(my_model, device)\n",
        "num_epochs = 9\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.0001\n",
        "filename=\"drive/MyDrive/training_dataset/resnet152_quality_2ch_normal_0.0001.pt\"\n",
        "patient_epochs=4\n",
        "history = fit(num_epochs, lr, model, train_loader, val_loader,filename,patient_epochs,restore_best_weights=True,opt_func=opt_func)\n",
        "end_time=perf_counter()\n",
        "print(f\"Elapsed time during the whole program in seconds: {end_time-start_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0x9hAuxJQ6g"
      },
      "outputs": [],
      "source": [
        "start_time=perf_counter()\n",
        "my_model = DenseNet121()\n",
        "model = to_device(my_model, device)\n",
        "num_epochs = 15\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001\n",
        "filename=\"drive/MyDrive/training_dataset/densenet121_450_quality_0.001.pt\"\n",
        "patient_epochs=5\n",
        "history = fit(num_epochs, lr, model, train_loader, val_loader,filename,patient_epochs,restore_best_weights=True,opt_func=opt_func)\n",
        "end_time=perf_counter()\n",
        "print(f\"Elapsed time during the whole program in seconds: {end_time-start_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apm_PE9muHI8"
      },
      "outputs": [],
      "source": [
        "def load_model_densenet(PATH):\n",
        "   torch.manual_seed(72)\n",
        "   my_model = DenseNet121()\n",
        "   my_model.load_state_dict(torch.load(PATH))\n",
        "   model = to_device(my_model, device)\n",
        "   model.eval()\n",
        "   return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfPr2loBbcB2"
      },
      "outputs": [],
      "source": [
        "def load_model_resnet152(PATH):\n",
        "   torch.manual_seed(72)\n",
        "   my_model = ResNet(Bottleneck, [3,8,36,3], num_classes=3, num_channels=3)\n",
        "   my_model.load_state_dict(torch.load(PATH))\n",
        "   model = to_device(my_model, device)\n",
        "   model.eval()\n",
        "   return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFBwXIvo9szk"
      },
      "outputs": [],
      "source": [
        "images,labels=create_tensor_test_set()\n",
        "test_ds=MyDataset(images=images,labels=labels)\n",
        "batch_size=16\n",
        "test_loader = DataLoader(test_ds, batch_size*2, num_workers=2, pin_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5tbStcTO4kj5"
      },
      "outputs": [],
      "source": [
        "model=load_model_densenet('drive/MyDrive/training_dataset/densenet121_450_0.001_best.pt')\n",
        "features=np.ones((32,1024))\n",
        "labels=np.ones(32)\n",
        "for batch in test_loader:\n",
        "    images, label = to_device(batch,device)\n",
        "    output = model.forward(images)\n",
        "    current_outputs = output.detach().numpy()\n",
        "    features = np.vstack((features, current_outputs))\n",
        "    labels = np.vstack((labels, label.cpu().numpy()))\n",
        "    print(features.shape)\n",
        "    print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deG_-8JU6FXI"
      },
      "outputs": [],
      "source": [
        "def load_model_vgg16(PATH):\n",
        "   torch.manual_seed(72)\n",
        "   my_model = ClassificationModel()\n",
        "   my_model.load_state_dict(torch.load(PATH))\n",
        "   model = to_device(my_model, device)\n",
        "   model.eval()\n",
        "   return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG4SQ3AzrhUo"
      },
      "outputs": [],
      "source": [
        "def fetch_image_quality(patient,option):\n",
        "    if patient<10:\n",
        "         file_name_4ch = 'drive/MyDrive/training_dataset/training/patient000'+str(patient)+'/Info_4CH.cfg'\n",
        "         file_name_2ch = 'drive/MyDrive/training_dataset/training/patient000' +str(patient) +'/Info_2CH.cfg'\n",
        "    elif patient<100 :\n",
        "         file_name_4ch = 'drive/MyDrive/training_dataset/training/patient00'+str(patient)+'/Info_4CH.cfg'\n",
        "         file_name_2ch = 'drive/MyDrive/training_dataset/training/patient00' +str(patient) +'/Info_2CH.cfg'\n",
        "    else :\n",
        "         file_name_4ch = 'drive/MyDrive/training_dataset/training/patient0'+str(patient)+'/Info_4CH.cfg'\n",
        "         file_name_2ch = 'drive/MyDrive/training_dataset/training/patient0' +str(patient) +'/Info_2CH.cfg'\n",
        "    if option=='4CH' :\n",
        "        with open(file_name_4ch) as f:\n",
        "           file_content = '[dummy_section]\\n' + f.read()\n",
        "        config_parser =configparser.RawConfigParser()\n",
        "        config_parser.read_string(file_content)\n",
        "        image_quality=config_parser['dummy_section']['ImageQuality']\n",
        "    else :\n",
        "        with open(file_name_2ch) as f:\n",
        "           file_content = '[dummy_section]\\n' + f.read()\n",
        "        config_parser =configparser.RawConfigParser()\n",
        "        config_parser.read_string(file_content)\n",
        "        image_quality=config_parser['dummy_section']['ImageQuality']\n",
        "    return image_quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7es42hgNy_2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import PredefinedSplit\n",
        "def logistic_classifier(X_train,Y_train,X_val,Y_val,filename):\n",
        "    split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
        "    X = np.concatenate((X_train, X_val), axis=0)\n",
        "    Y = np.concatenate((Y_train, Y_val), axis=0)\n",
        "    pds = PredefinedSplit(test_fold = split_index)\n",
        "    clf=LogisticRegression(multi_class='ovr')\n",
        "    param_grid={\n",
        "                \"C\" : np.logspace(-4,4,40),\n",
        "                \"solver\":[\"lbfgs\"],\n",
        "                \"max_iter\":[100,200,300]\n",
        "                }\n",
        "    optimum_model=GridSearchCV(clf,param_grid=param_grid,cv=pds,n_jobs=-1)\n",
        "    optimum_model.fit(X,Y)\n",
        "    save_sklearn_model(optimum_model,filename)\n",
        "    return optimum_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LqGY_Qb3G97"
      },
      "outputs": [],
      "source": [
        "def quality_logistic_classifier(X_train,Y_train,filename):\n",
        "    clf=LogisticRegression()\n",
        "    param_grid={\n",
        "                \"C\" : np.logspace(-4,4,40),\n",
        "                \"solver\":[\"lbfgs\"],\n",
        "                \"max_iter\":[100,300,400,500]\n",
        "                }\n",
        "    optimum_model=GridSearchCV(clf,param_grid=param_grid,cv=10,n_jobs=-1)\n",
        "    optimum_model.fit(X_train,Y_train)\n",
        "    save_sklearn_model(optimum_model,filename)\n",
        "    return optimum_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Lhe6BI6lEIY"
      },
      "outputs": [],
      "source": [
        "def save_sklearn_model(model,filename):\n",
        "    pickle.dump(model, open(filename, 'wb'))\n",
        "def load_sklearn_model(filename):\n",
        "    loaded_model = pickle.load(open(filename, 'rb'))\n",
        "    return loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOcxR-h7NrRC"
      },
      "outputs": [],
      "source": [
        "def hog_classification_train():\n",
        "  X_train,Y_train=create_hog_dataset_dataframe(X_train_dataframe)\n",
        "  X_val,Y_val=create_hog_dataset_dataframe(Val_set_dataframe)\n",
        "  #X_test,Y_test=create_hog_dataset_test(patients=51)\n",
        "  filename='drive/MyDrive/training_dataset/logistic_classifier_450_4_hog.sav'\n",
        "  clf=logistic_classifier(X_train,Y_train,X_val,Y_val,filename)\n",
        "  sklearn_performance_metrics(clf,X_test,Y_test,binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urnwcOhgbyfZ"
      },
      "outputs": [],
      "source": [
        "X,Y=create_hog_dataset_test(patients=51)\n",
        "sklearn_performance_metrics(clf,X_test,Y_test,binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cQEakQItl-m"
      },
      "outputs": [],
      "source": [
        "def create_hog_dataset_test(patients):\n",
        "  hog_features_4CH=[]\n",
        "  hog_features_2CH=[]\n",
        "  for patient in range(1,patients):\n",
        "    image_4ch_file=fetch_test_file(patient=patient,option='4CH')\n",
        "    image_2ch_file=fetch_test_file(patient=patient,option='2CH')\n",
        "    image_4ch=get_array(image_4ch_file)\n",
        "    image_2ch=get_array(image_2ch_file)\n",
        "    for j in range(image_4ch.shape[0]):\n",
        "        #rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        rgb_image = image_4ch[j,:,:]\n",
        "        image=preprocessing(rgb_image).numpy()\n",
        "        hog_features = []\n",
        "        for channel in range(1):\n",
        "            hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,\n",
        "                                        orientations=9,pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "            hog_features.append(hog_feature)\n",
        "        hog_features_4CH.append(np.ravel(hog_features))\n",
        "    for j in range(image_2ch.shape[0]):\n",
        "        #rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        rgb_image = image_2ch[j,:,:]\n",
        "        image=preprocessing(rgb_image).numpy()\n",
        "        hog_features = []\n",
        "        for channel in range(1):\n",
        "            hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,\n",
        "                                        orientations=9,pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "            hog_features.append(hog_feature)\n",
        "        hog_features_2CH.append(np.ravel(hog_features))\n",
        "  X = np.vstack((hog_features_4CH, hog_features_2CH)).astype(np.float64)\n",
        "  Y = np.hstack((np.zeros(len(hog_features_4CH)), np.ones(len(hog_features_2CH)))).astype(int)\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA9iWqUB73s3"
      },
      "outputs": [],
      "source": [
        "def create_hog_dataset(patients):\n",
        "  hog_features_4CH=[]\n",
        "  hog_features_2CH=[]\n",
        "  for patient in range(1,patients):\n",
        "    image_4ch_file=fetch_file(patient=patient,option='4CH')\n",
        "    image_2ch_file=fetch_file(patient=patient,option='2CH')\n",
        "    image_4ch=get_array(image_4ch_file)\n",
        "    image_2ch=get_array(image_2ch_file)\n",
        "    for j in range(image_4ch.shape[0]):\n",
        "        #rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        rgb_image = image_4ch[j,:,:]\n",
        "        image=preprocessing(rgb_image).numpy()\n",
        "        hog_features = []\n",
        "        for channel in range(1):\n",
        "            hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,\n",
        "                                        orientations=9,pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "            hog_features.append(hog_feature)\n",
        "        hog_features_4CH.append(np.ravel(hog_features))\n",
        "    for j in range(image_2ch.shape[0]):\n",
        "        #rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        rgb_image = image_2ch[j,:,:]\n",
        "        image=preprocessing(rgb_image).numpy()\n",
        "        hog_features = []\n",
        "        for channel in range(1):\n",
        "            hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,\n",
        "                                        orientations=9,pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "            hog_features.append(hog_feature)\n",
        "        hog_features_2CH.append(np.ravel(hog_features))\n",
        "  X = np.vstack((hog_features_4CH, hog_features_2CH)).astype(np.float64)\n",
        "  Y = np.hstack((np.zeros(len(hog_features_4CH)), np.ones(len(hog_features_2CH)))).astype(int)\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2bcSIPuzIlK"
      },
      "outputs": [],
      "source": [
        "def create_hog_dataset_dataframe(dataframe):\n",
        "  hog_features_4CH=[]\n",
        "  hog_features_2CH=[]\n",
        "  for patient in dataframe['patient']:\n",
        "    image_4ch_file=fetch_file(patient=patient,option='4CH')\n",
        "    image_2ch_file=fetch_file(patient=patient,option='2CH')\n",
        "    image_4ch=get_array(image_4ch_file)\n",
        "    image_2ch=get_array(image_2ch_file)\n",
        "    for j in range(image_4ch.shape[0]):\n",
        "        #rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        rgb_image = image_4ch[j,:,:]\n",
        "        image=preprocessing(rgb_image).numpy()\n",
        "        hog_features = []\n",
        "        for channel in range(1):\n",
        "            hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,\n",
        "                                        orientations=9,pixels_per_cell=(8,8),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "            hog_features.append(hog_feature)\n",
        "        hog_features_4CH.append(np.ravel(hog_features))\n",
        "    for j in range(image_2ch.shape[0]):\n",
        "        #rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        rgb_image = image_2ch[j,:,:]\n",
        "        image=preprocessing(rgb_image).numpy()\n",
        "        hog_features = []\n",
        "        for channel in range(1):\n",
        "            hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,\n",
        "                                        orientations=9,pixels_per_cell=(8,8),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "            hog_features.append(hog_feature)\n",
        "        hog_features_2CH.append(np.ravel(hog_features))\n",
        "  X = np.vstack((hog_features_4CH, hog_features_2CH)).astype(np.float64)\n",
        "  Y = np.hstack((np.zeros(len(hog_features_4CH)), np.ones(len(hog_features_2CH)))).astype(int)\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZptl9lNy0-D"
      },
      "outputs": [],
      "source": [
        "for patient in X_train_dataframe['patient']:\n",
        "  print(patient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoHafsO0uPKH"
      },
      "outputs": [],
      "source": [
        "def create_hog_dataset_quality(dataframe):\n",
        "  hog_features_4CH=[]\n",
        "  hog_features_2CH=[]\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for patient in dataframe['patient']:\n",
        "    #image_4ch_file=fetch_file(patient=patient,option='4CH')\n",
        "    image_2ch_file=fetch_file(patient=patient,option='2CH')\n",
        "    #image_4ch=get_array(image_4ch_file)\n",
        "    image_2ch=get_array(image_2ch_file)\n",
        "    #image_4ch_quality=fetch_image_quality(patient=patient,option='4CH')\n",
        "    image_2ch_quality=fetch_image_quality(patient=patient,option='2CH')\n",
        "    #label_4ch=get_image_quality_label(image_4ch_quality)\n",
        "    label_2ch=get_image_quality_label(image_2ch_quality)\n",
        "    #for j in range(image_4ch.shape[0]):\n",
        "        #rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        #rgb_image= image_4ch[j,:,:]\n",
        "        #image=preprocessing(rgb_image).numpy()\n",
        "        #hog_features = []\n",
        "        #for channel in range(1):\n",
        "            #hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,orientations=9,\n",
        "                                        #pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                                        #visualize=True,feature_vector=True)\n",
        "            #hog_features.append(hog_feature)\n",
        "        #X.append(np.ravel(hog_features))\n",
        "        #Y.append(label_4ch)\n",
        "    for j in range(image_2ch.shape[0]):\n",
        "        rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        rgb_image= image_2ch[j,:,:]\n",
        "        image=preprocessing(rgb_image).numpy()\n",
        "        hog_features = []\n",
        "        for channel in range(1):\n",
        "            hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,orientations=9,\n",
        "                                        pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "            hog_features.append(hog_feature)\n",
        "        X.append(np.ravel(hog_features))\n",
        "        Y.append(label_2ch)\n",
        "  print(X)\n",
        "  X = np.array(X)\n",
        "  Y = np.array(Y)\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAd1KX760svb"
      },
      "outputs": [],
      "source": [
        "def create_hog_dataset_quality_test(patients):\n",
        "  hog_features_4CH=[]\n",
        "  hog_features_2CH=[]\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for patient in range(1,patients):\n",
        "    #image_4ch_file=fetch_test_file(patient=patient,option='4CH')\n",
        "    image_2ch_file=fetch_test_file(patient=patient,option='2CH')\n",
        "    #image_4ch=get_array(image_4ch_file)\n",
        "    image_2ch=get_array(image_2ch_file)\n",
        "    #image_4ch_quality=fetch_test_image_quality(patient=patient,option='4CH')\n",
        "    image_2ch_quality=fetch_test_image_quality(patient=patient,option='2CH')\n",
        "    #label_4ch=get_image_quality_label(image_4ch_quality)\n",
        "    label_2ch=get_image_quality_label(image_2ch_quality)\n",
        "    #for j in range(image_4ch.shape[0]):\n",
        "        #rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        #rgb_image=image_4ch[j,:,:]\n",
        "        #image=preprocessing(rgb_image).numpy()\n",
        "        #hog_features = []\n",
        "        #for channel in range(1):\n",
        "            #hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,orientations=9,\n",
        "             #                           pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "              #                          visualize=True,feature_vector=True)\n",
        "            #hog_features.append(hog_feature)\n",
        "        #X.append(np.ravel(hog_features))\n",
        "        #Y.append(label_4ch)\n",
        "    for j in range(image_2ch.shape[0]):\n",
        "        rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "        rgb_image=image_2ch[j,:,:]\n",
        "        image=preprocessing(rgb_image).numpy()\n",
        "        hog_features = []\n",
        "        for channel in range(1):\n",
        "            hog_feature,hog_image = hog(image[channel,:,:],transform_sqrt=False,orientations=9,\n",
        "                                       pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                                       visualize=True,feature_vector=True)\n",
        "            hog_features.append(hog_feature)\n",
        "        X.append(np.ravel(hog_features))\n",
        "        Y.append(label_2ch)\n",
        "  print(X)\n",
        "  X = np.array(X)\n",
        "  Y = np.array(Y)\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oELn6dmeIGiX"
      },
      "outputs": [],
      "source": [
        "X_test,Y_test=create_hog_dataset_quality_test(patients=51)\n",
        "filename='drive/MyDrive/training_dataset/logistic_classifier_2ch_under2_quality_hog.sav'\n",
        "model=load_sklearn_model(filename)\n",
        "sklearn_performance_metrics(model,X_test,Y_test,binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvhSQkf7IjC-"
      },
      "outputs": [],
      "source": [
        "def poor_quality_counter(clf,X_test,Y_test):\n",
        "  Y_pred=clf.predict(X_test)\n",
        "  size=Y_pred.shape[0]\n",
        "  good=Y_pred[Y_pred == 0]\n",
        "  medium=Y_pred[Y_pred == 1]\n",
        "  print(f\"Size is {size}\")\n",
        "  print(good.shape[0]/size)\n",
        "  print(medium.shape[0]/size)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyPcgCB6MdA3"
      },
      "outputs": [],
      "source": [
        "def hog_classification_quality_train():\n",
        "  X_train,Y_train=create_hog_dataset_quality(X_train_dataframe)\n",
        "  X_train,Y_train=sampling_strategy(X_train,Y_train)\n",
        "  X_val,Y_val=create_hog_dataset_quality(Val_set_dataframe)\n",
        "  print(X_train.shape)\n",
        "  X_test,Y_test=create_hog_dataset_quality_test(patients=51)\n",
        "  print(X_train.shape)\n",
        "  filename='drive/MyDrive/training_dataset/logistic_classifier_2ch_4_under_quality_hog.sav'\n",
        "  clf=logistic_classifier(X_train,Y_train,X_val,Y_val,filename)\n",
        "  sklearn_performance_metrics(clf,X_test,Y_test,binary= False)\n",
        "\n",
        "hog_classification_quality_train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5lpe7vR5OP9"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "def sampling_strategy(X_train,Y_train):\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_res, Y_res = ros.fit_resample(X_train, Y_train)\n",
        "    return X_res,Y_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GEN-s4mn16t"
      },
      "outputs": [],
      "source": [
        "def sklearn_performance_metrics(model,X_test,Y_test,binary):\n",
        "  labels=[\"Good\",\"Medium\",\"Poor\"]\n",
        "  Y_pred=model.predict(X_test)\n",
        "  if binary == True :\n",
        "      #print(roc_auc_score(Y_test, model.predict_proba(X_test)[:, 1]))\n",
        "      labels=['4CH','2CH']\n",
        "  #print(accuracy_score(Y_test,Y_pred))\n",
        "  print(balanced_accuracy_score(Y_test,Y_pred))\n",
        "  print(classification_report(Y_test, Y_pred, target_names=labels))\n",
        "  print(confusion_matrix(Y_test, Y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBdyX7JOZfGj"
      },
      "outputs": [],
      "source": [
        "def patients_quality_images(view_option,quality_option):\n",
        "    patient_list=[]\n",
        "    total_patients=451\n",
        "    total=0\n",
        "    for patient in range(1,total_patients):\n",
        "      image_quality=fetch_image_quality(patient,option=view_option)\n",
        "      if image_quality == quality_option:\n",
        "         patient_list.append(patient)\n",
        "      else:\n",
        "        pass\n",
        "    return patient_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLgk03hjVadr"
      },
      "outputs": [],
      "source": [
        "def create_hog_dataset_test_quality_testing(quality_option,view_option):\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for patient in range(1,51):\n",
        "    image_quality=fetch_test_image_quality(patient=patient,option=view_option)\n",
        "    if image_quality != quality_option:\n",
        "       continue\n",
        "    label=get_image_quality_label(image_quality)\n",
        "    image_file=fetch_test_file(patient=patient,option=view_option)\n",
        "    image=get_array(image_file)\n",
        "    for j in range(image.shape[0]):\n",
        "        test_image = image[j,:,:]\n",
        "        test_image=preprocessing(test_image).numpy()\n",
        "        for channel in range(1):\n",
        "            hog_feature,hog_image = hog(test_image[channel,:,:],transform_sqrt=False,\n",
        "                                        orientations=9,pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "        X.append(hog_feature)\n",
        "        Y.append(label)\n",
        "  X=np.array(X)\n",
        "  Y=np.array(Y)\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQSUdT9pwEyy"
      },
      "outputs": [],
      "source": [
        "def sklearn_test_dataset_performance(X_test,Y_test):\n",
        "    filename='drive/MyDrive/training_dataset/logistic_classifier_hog.sav'\n",
        "    model=load_sklearn_model(filename)\n",
        "    sklearn_performance_metrics(model,X_test,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y3jTDGcc1yt"
      },
      "outputs": [],
      "source": [
        "category_view={\n",
        "       '4CH':0,\n",
        "       '2CH':1\n",
        "   }\n",
        "filename='drive/MyDrive/training_dataset/logistic_classifier_450_hog.sav'\n",
        "model=load_sklearn_model(filename)\n",
        "for view_option in [\"4CH\",\"2CH\"]:\n",
        "    for quality in ['Good','Medium','Poor']:\n",
        "        X_test,Y_test=create_hog_dataset_test_quality_testing(quality_option=quality,view_option=view_option)\n",
        "        Y_pred=model.predict(X_test)\n",
        "        view=category_view[view_option]\n",
        "        correct=Y_pred[Y_pred == view ]\n",
        "        print(f\"{view_option} in the {quality} quality are correctly classified {correct.shape[0]/Y_pred.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD_vEBAy-aFy"
      },
      "outputs": [],
      "source": [
        "def sklearn_video_level_classification(patient,model):\n",
        "  image_4ch_file=fetch_test_file(patient=patient,option='4CH')\n",
        "  image_2ch_file=fetch_test_file(patient=patient,option='2CH')\n",
        "  image_4ch=get_array(image_4ch_file)\n",
        "  image_2ch=get_array(image_2ch_file)\n",
        "  correct_4ch=0\n",
        "  correct_2ch=0\n",
        "  for j in range(image_4ch.shape[0]):\n",
        "    X=[]\n",
        "    #rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "    rgb_image=image_4ch[j,:,:]\n",
        "    image=preprocessing(rgb_image).numpy()\n",
        "    hog_features = []\n",
        "    for channel in range(1):\n",
        "        hog_feature = hog(image[channel,:,:],transform_sqrt=False,orientations=9,pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                          visualize=False,feature_vector=True)\n",
        "        hog_features.append(hog_feature)\n",
        "    X.append(np.ravel(hog_features))\n",
        "    prediction=model.predict(X)[0]\n",
        "    if prediction == 0:\n",
        "      correct_4ch = correct_4ch + 1\n",
        "  for j in range(image_2ch.shape[0]):\n",
        "    X=[]\n",
        "    #rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "    rgb_image=image_2ch[j,:,:]\n",
        "    image=preprocessing(rgb_image).numpy()\n",
        "    hog_features = []\n",
        "    for channel in range(1):\n",
        "        hog_feature = hog(image[channel,:,:],transform_sqrt=False,orientations=9,pixels_per_cell=(16,16),cells_per_block=(2, 2),\n",
        "                          visualize=False,feature_vector=True)\n",
        "        hog_features.append(hog_feature)\n",
        "    X.append(np.ravel(hog_features))\n",
        "    prediction=model.predict(X)[0]\n",
        "    if prediction == 1 :\n",
        "      correct_2ch = correct_2ch + 1\n",
        "  print(f\"4ch success rate {correct_4ch/image_4ch.shape[0]}\")\n",
        "  print(f\"2ch success rate {correct_2ch/image_2ch.shape[0]}\")\n",
        "  return correct_4ch/image_4ch.shape[0],correct_2ch/image_2ch.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9N4_iHe973K"
      },
      "outputs": [],
      "source": [
        "filename='drive/MyDrive/training_dataset/logistic_classifier_450_hog.sav'\n",
        "model=load_sklearn_model(filename)\n",
        "patients_4ch=list()\n",
        "patients_2ch=list()\n",
        "for patient in range(1,51):\n",
        "    video_4ch,video_2ch=sklearn_video_level_classification(patient=patient,model=model)\n",
        "    patients_4ch.append(video_4ch)\n",
        "    patients_2ch.append(video_2ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33FjfAHIK-R4"
      },
      "outputs": [],
      "source": [
        "patients_4ch=np.array(patients_4ch)\n",
        "print(patients_4ch.shape)\n",
        "print(patients_4ch[patients_4ch==1].shape)\n",
        "print(patients_4ch[patients_4ch<1])\n",
        "print(patients_4ch[patients_4ch<1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHEfyDdYBFtI"
      },
      "outputs": [],
      "source": [
        "patient_4ch = pd.Series(patients_4ch*100)\n",
        "\n",
        "patient_4ch.plot.hist(grid=True, bins=30, rwidth=0.9,\n",
        "                   color='#607c8e')\n",
        "plt.title('Video Success precentages for 4ch Chamber view')\n",
        "plt.xlabel('Percentage of Correct Classification')\n",
        "plt.ylabel('Number of Videos')\n",
        "plt.grid(axis='y', alpha=0.75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mqDOqClB_0U"
      },
      "outputs": [],
      "source": [
        "patient_2ch = pd.Series(np.array(patients_2ch)*100)\n",
        "\n",
        "patient_2ch.plot.hist(grid=True, bins=30, rwidth=0.9,\n",
        "                   color='#607c8e')\n",
        "plt.title('Video Success precentages for 2ch Chamber view')\n",
        "plt.xlabel('Percentage of Correct Classification')\n",
        "plt.ylabel('Number of Videos')\n",
        "plt.grid(axis='y', alpha=0.75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5-tPo4EEnEe"
      },
      "outputs": [],
      "source": [
        "def video_level_classification_performance(patients,model):\n",
        "    video_4ch=[]\n",
        "    video_2ch=[]\n",
        "    for patient in range(1,patients):\n",
        "        correct_4ch,correct_2ch=sklearn_video_level_classification(patient,model)\n",
        "        video_4ch.append(correct_4ch)\n",
        "        video_2ch.append(correct_2ch)\n",
        "    print(video_4ch)\n",
        "    print(video_2ch)\n",
        "    print(len(video_4ch))\n",
        "    video_3dplot(patients,video_4ch,video_2ch)\n",
        "\n",
        "filename='drive/MyDrive/training_dataset/logistic_classifier_450_hog.sav'\n",
        "model=load_sklearn_model(filename)\n",
        "video_level_classification_performance(451,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a2RHip9MdS1"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.colors import ListedColormap\n",
        "def video_3dplot(patients,video_4ch,video_2ch):\n",
        "    x=video_4ch\n",
        "    y=video_2ch\n",
        "    z=range(1,patients)\n",
        "    fig = plt.figure(figsize=(6,6))\n",
        "    ax = Axes3D(fig)\n",
        "    fig.add_axes(ax)\n",
        "    cmap = ListedColormap(sns.color_palette(\"husl\", 256).as_hex())\n",
        "    sc = ax.scatter(x, y, z, s=40, c=x, marker='o', cmap=cmap, alpha=1)\n",
        "    ax.set_xlabel('X Label')\n",
        "    ax.set_ylabel('Y Label')\n",
        "    ax.set_zlabel('Z Label')\n",
        "    plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwOFJo0nw28n"
      },
      "outputs": [],
      "source": [
        "def resnet_pretrained():\n",
        "   model_frozen = torchvision.models.resnet18(pretrained=True)\n",
        "   for param in model_frozen.parameters():\n",
        "      param.requires_grad = False\n",
        "   model_frozen.fc = nn.Linear(model_frozen.fc.in_features, 2)\n",
        "   return model_frozen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "it1ldPeFmJyl"
      },
      "outputs": [],
      "source": [
        "def vgg16_pretrained():\n",
        "   model_frozen = torchvision.models.vgg16(pretrained=True)\n",
        "   for param in model_frozen.parameters():\n",
        "      param.requires_grad = False\n",
        "   n_inputs = model_frozen.classifier[6].in_features\n",
        "   model_frozen.classifier[6] = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.7),\n",
        "    nn.Linear(256, 2), nn.LogSoftmax(dim=1))\n",
        "   return model_frozen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XydLLV7aO0JI"
      },
      "outputs": [],
      "source": [
        "def densenet_pretrained():\n",
        "   model_frozen = torchvision.models.densenet161(pretrained=True)\n",
        "   for param in model_frozen.parameters():\n",
        "      param.requires_grad = False\n",
        "   in_features = model_frozen.classifier.in_features\n",
        "   model_frozen.classifier = nn.Linear(in_features, 2)\n",
        "   return model_frozen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khOpfE7nv2L5"
      },
      "outputs": [],
      "source": [
        "def efficient_net_pretrained():\n",
        "   model_frozen = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "   for param in model_frozen.parameters():\n",
        "      param.requires_grad = False\n",
        "   model_frozen.classifier[1] = nn.Linear(in_features=1280, out_features=2)\n",
        "   return model_frozen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEHPVGrR-ZW3"
      },
      "outputs": [],
      "source": [
        "def training_pretrained(pretrained_model,train_loader,val_loader,test_loader):\n",
        "   model=pretrained_model\n",
        "   device=get_default_device()\n",
        "   model = to_device(model, device)\n",
        "   num_epochs = 10\n",
        "   opt_func = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "   loss_fn = torch.nn.CrossEntropyLoss()\n",
        "   PATH=\"drive/MyDrive/training_dataset/resnet_pretrained.pt\"\n",
        "   train_pretrained(model = model, numepochs = num_epochs,\n",
        "                           train_loader = train_loader,val_loader = val_loader,\n",
        "                           optimizer = opt_func,lossfun = loss_fn)\n",
        "\n",
        "model=efficient_net_pretrained()\n",
        "training_pretrained(pretrained_model=model,train_loader=train_loader,val_loader=val_loader,test_loader=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJQZEvvBAseb"
      },
      "outputs": [],
      "source": [
        "def train_pretrained(model,numepochs,train_loader,val_loader,optimizer,lossfun):\n",
        "  trainloss=torch.zeros(numepochs)\n",
        "  valloss=torch.zeros(numepochs)\n",
        "  trainacc=torch.zeros(numepochs)\n",
        "  valacc=torch.zeros(numepochs)\n",
        "  for epochi in range(numepochs):\n",
        "    model.train()\n",
        "    batchloss=[]\n",
        "    batchacc=[]\n",
        "    for batch in train_loader:\n",
        "      X, Y = to_device(batch,device)\n",
        "      yhat=model(X)\n",
        "      loss=lossfun(yhat,Y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      batchloss.append(loss.item())\n",
        "      batchacc.append(torch.mean((torch.argmax(yhat,axis=1)==Y).float()).item())\n",
        "    trainloss[epochi]=np.mean(batchloss)\n",
        "    trainacc[epochi]=100*np.mean(batchacc)\n",
        "    model.eval()\n",
        "    batchacc=[]\n",
        "    batchloss=[]\n",
        "    for batch in val_loader:\n",
        "      X, Y = to_device(batch,device)\n",
        "      with torch.no_grad():\n",
        "        yhat=model(X)\n",
        "        loss=lossfun(yhat,Y)\n",
        "      batchloss.append(loss.item())\n",
        "      batchacc.append(torch.mean((torch.argmax(yhat,axis=1)==Y).float()).item())\n",
        "    valloss[epochi]=np.mean(batchloss)\n",
        "    valacc[epochi]=100*np.mean(batchacc)\n",
        "    print(f'Finished epoch{epochi + 1 }/{numepochs}.Val accuracy={valacc[epochi]:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eyr5fXPwVRm"
      },
      "outputs": [],
      "source": [
        "def visualize2DSoftmax(X, y, model, title=None):\n",
        "    x_min = np.min(X[:,0])-0.5\n",
        "    x_max = np.max(X[:,0])+0.5\n",
        "    y_min = np.min(X[:,1])-0.5\n",
        "    y_max = np.max(X[:,1])+0.5\n",
        "    xv, yv = np.meshgrid(np.linspace(x_min, x_max, num=20),np.linspace(y_min, y_max, num=20), indexing='ij')\n",
        "    xy_v = np.hstack((xv.reshape(-1,1), yv.reshape(-1,1)))\n",
        "    with torch.no_grad():\n",
        "        logits = model(torch.tensor(xy_v, dtype=torch.float32))\n",
        "        y_hat = F.softmax(logits, dim=1).numpy()\n",
        "    cs = plt.contourf(xv, yv, y_hat[:,0].reshape(20,20),levels=np.linspace(0,1,num=20), cmap=plt.cm.RdYlBu)\n",
        "    ax = plt.gca()\n",
        "    sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, style=y, ax=ax)\n",
        "    if title is not None:\n",
        "        ax.set_title(title)\n",
        "\n",
        "visualize2DSoftmax(X, y, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXwt9lBAP14z"
      },
      "outputs": [],
      "source": [
        "class MyDataset_Autoencoder(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, transform=None):\n",
        "        self.images = images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.images[index]\n",
        "\n",
        "        if self.transform:\n",
        "            x = Image.fromarray(self.images[index].astype(np.uint8).transpose(1, 2, 0))\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGbZdEj_Ravo"
      },
      "outputs": [],
      "source": [
        "def autoencoder_train_loader():\n",
        "   images,_=create_tensor_set(dataframe)\n",
        "   train_ds=MyDataset_Autoencoder(images=images)\n",
        "   batch_size=32\n",
        "   train_loader = DataLoader(train_ds, batch_size,shuffle=True,num_workers=4, pin_memory=True)\n",
        "   return train_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb61GVlPLIdz"
      },
      "outputs": [],
      "source": [
        "def convolutional_autoencoder_train():\n",
        "  train_loader=autoencoder_train_loader()\n",
        "  model=Convolutional_Autoencoder()\n",
        "  model = to_device(model, device)\n",
        "  num_epochs = 10\n",
        "  criterian=nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters())\n",
        "  covnolutional_autoencoder_training(model=model,train_dataloader=train_loader,epochs=num_epochs,optimizer=optimizer,criterian=criterian)\n",
        "  torch.save(model.state_dict(),'autoencoder.h5')\n",
        "\n",
        "device=get_default_device()\n",
        "convolutional_autoencoder_train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaNKWj5SOofk"
      },
      "outputs": [],
      "source": [
        "def covnolutional_autoencoder_training(model,train_dataloader,epochs,optimizer,criterian):\n",
        "    for epoch in range(epochs):\n",
        "       model.train()\n",
        "       iteration = 0\n",
        "       for data in train_dataloader:\n",
        "           optimizer.zero_grad()\n",
        "           data = to_device(data,device)\n",
        "           output = model.forward(data)\n",
        "           loss = criterian(output,data)\n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           if iteration%1000 == 0:\n",
        "              print(f'iteration: {iteration} , loss : {loss.item()}')\n",
        "       print(f'epoch: {epoch} loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX_7p2hhTPZ6"
      },
      "outputs": [],
      "source": [
        "def roc_curve_sklearn():\n",
        "   test_probs_max = []\n",
        "   for i in range(test_probs.shape[0]):\n",
        "      test_probs_max.append(test_probs[i,test_y[i]])\n",
        "   fpr, tpr, thresholds = roc_curve(test_y, np.array(test_probs_max))\n",
        "   fig,ax = plt.subplots()\n",
        "   plt.plot(fpr,tpr,label='ROC curve')\n",
        "   plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "   plt.xlabel('False Positive Rate')\n",
        "   plt.ylabel('True Positive Rate')\n",
        "   plt.title('Receiver Operating Characteristic for Email Example')\n",
        "   plt.legend(loc=\"lower right\")\n",
        "   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mGR5f9lERFI"
      },
      "outputs": [],
      "source": [
        "def saliency_map(image,model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    model.eval()\n",
        "    input = preprocessing(img)\n",
        "    input.unsqueeze_(0)\n",
        "    input.requires_grad = True\n",
        "    preds = model(input)\n",
        "    score, indices = torch.max(preds, 1)\n",
        "    score.backward()\n",
        "    slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)\n",
        "    slc = (slc - slc.min())/(slc.max()-slc.min())\n",
        "     with torch.no_grad():\n",
        "        input_img = inv_normalize(input[0])\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(np.transpose(input_img.detach().numpy(), (1, 2, 0)))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(slc.numpy(), cmap=plt.cm.hot)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIW2XFgZLxJm"
      },
      "outputs": [],
      "source": [
        "nb_frames_4ch_list=[]\n",
        "nb_frames_2ch_list=[]\n",
        "ages_list=[]\n",
        "sex_list=[]\n",
        "image_quality_4ch_list=[]\n",
        "image_quality_2ch_list=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_Fxl0tlLxWB"
      },
      "outputs": [],
      "source": [
        "for i in range(1,51):\n",
        "    if i<10:\n",
        "         file_name_4ch= 'drive/MyDrive/testing_dataset/testing/patient000'+str(i)+'/Info_4CH.cfg'\n",
        "         file_name_2ch= 'drive/MyDrive/testing_dataset/testing/patient000' +str(i) +'/Info_2CH.cfg'\n",
        "    else  :\n",
        "         file_name_4ch= 'drive/MyDrive/testing_dataset/testing/patient00'+str(i)+'/Info_4CH.cfg'\n",
        "         file_name_2ch= 'drive/MyDrive/testing_dataset/testing/patient00' +str(i) +'/Info_2CH.cfg'\n",
        "    with open(file_name_4ch) as f:\n",
        "        file_content = '[dummy_section]\\n' + f.read()\n",
        "    config_parser =configparser.RawConfigParser()\n",
        "    config_parser.read_string(file_content)\n",
        "    ages_list.append(int(config_parser['dummy_section']['Age']))\n",
        "    sex_list.append(config_parser['dummy_section']['Sex'])\n",
        "    nb_frames_4ch_list.append(int(config_parser['dummy_section']['NbFrame']))\n",
        "    image_quality_4ch_list.append(config_parser['dummy_section']['ImageQuality'])\n",
        "    with open(file_name_2ch) as f:\n",
        "        file_content = '[dummy_section]\\n' + f.read()\n",
        "    config_parser =configparser.RawConfigParser()\n",
        "    config_parser.read_string(file_content)\n",
        "    nb_frames_2ch_list.append(int(config_parser['dummy_section']['NbFrame']))\n",
        "    image_quality_2ch_list.append(config_parser['dummy_section']['ImageQuality'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL_wzRwkLyBz"
      },
      "outputs": [],
      "source": [
        "dataframe_test=pd.DataFrame({'Age':ages_list,'Sex':sex_list,'Image_quality_4ch':image_quality_4ch_list,'Nb_frames_4ch':nb_frames_4ch_list,'Image_quality_2ch':image_quality_2ch_list,'Nb_frames_2ch':nb_frames_2ch_list})\n",
        "dataframe_test['patient']=range(1,51)\n",
        "print(dataframe_test)\n",
        "print(\"Total 4ch examples\")\n",
        "size=len(dataframe_test)\n",
        "print(dataframe_test['Nb_frames_4ch'].sum())\n",
        "print(\"Total 2ch examples\")\n",
        "print(dataframe_test['Nb_frames_2ch'].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5j2j62YM90e"
      },
      "outputs": [],
      "source": [
        "print(dataframe_test['Image_quality_4ch'].value_counts())\n",
        "print(dataframe_test['Image_quality_2ch'].value_counts())\n",
        "print(dataframe_test['Sex'].value_counts())\n",
        "print(dataframe_test[\"Nb_frames_4ch\"].loc[dataframe_test[\"Image_quality_4ch\"] == \"Poor\" ].sum())\n",
        "print(dataframe_test[\"Nb_frames_4ch\"].loc[dataframe_test[\"Image_quality_4ch\"] == \"Medium\" ].sum())\n",
        "print(dataframe_test[\"Nb_frames_4ch\"].loc[dataframe_test[\"Image_quality_4ch\"] == \"Good\" ].sum())\n",
        "print(dataframe_test[\"Nb_frames_2ch\"].loc[dataframe_test[\"Image_quality_2ch\"] == \"Poor\" ].sum())\n",
        "print(dataframe_test[\"Nb_frames_2ch\"].loc[dataframe_test[\"Image_quality_2ch\"] == \"Medium\" ].sum())\n",
        "print(dataframe_test[\"Nb_frames_2ch\"].loc[dataframe_test[\"Image_quality_2ch\"] == \"Good\" ].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bO6X6kIkpkP"
      },
      "outputs": [],
      "source": [
        "def fetch_test_file(patient,option):\n",
        "      if patient >= 10 :\n",
        "          image_path_4ch = \"drive/MyDrive/testing_dataset/testing/patient00\"+str(patient)+\"/patient00\"+str(patient)+\"_4CH_sequence.mhd\"\n",
        "          image_path_2ch = \"drive/MyDrive/testing_dataset/testing/patient00\"+str(patient)+\"/patient00\"+str(patient)+\"_2CH_sequence.mhd\"\n",
        "      else:\n",
        "          image_path_4ch = \"drive/MyDrive/testing_dataset/testing/patient000\"+str(patient)+\"/patient000\"+str(patient)+\"_4CH_sequence.mhd\"\n",
        "          image_path_2ch = \"drive/MyDrive/testing_dataset/testing/patient000\"+str(patient)+\"/patient000\"+str(patient)+\"_2CH_sequence.mhd\"\n",
        "      if option=='4CH' :\n",
        "         image_path=image_path_4ch\n",
        "      else :\n",
        "         image_path=image_path_2ch\n",
        "      return image_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spP98m8FmrMk"
      },
      "outputs": [],
      "source": [
        "def fetch_test_image_quality(patient,option):\n",
        "    if patient<10:\n",
        "         file_name_4ch = 'drive/MyDrive/testing_dataset/testing/patient000'+str(patient)+'/Info_4CH.cfg'\n",
        "         file_name_2ch = 'drive/MyDrive/testing_dataset/testing/patient000' +str(patient) +'/Info_2CH.cfg'\n",
        "    else :\n",
        "         file_name_4ch = 'drive/MyDrive/testing_dataset/testing/patient00'+str(patient)+'/Info_4CH.cfg'\n",
        "         file_name_2ch = 'drive/MyDrive/testing_dataset/testing/patient00' +str(patient) +'/Info_2CH.cfg'\n",
        "    if option == '4CH' :\n",
        "        with open(file_name_4ch) as f:\n",
        "           file_content = '[dummy_section]\\n' + f.read()\n",
        "        config_parser =configparser.RawConfigParser()\n",
        "        config_parser.read_string(file_content)\n",
        "        image_quality=config_parser['dummy_section']['ImageQuality']\n",
        "    else :\n",
        "        with open(file_name_2ch) as f:\n",
        "           file_content = '[dummy_section]\\n' + f.read()\n",
        "        config_parser =configparser.RawConfigParser()\n",
        "        config_parser.read_string(file_content)\n",
        "        image_quality=config_parser['dummy_section']['ImageQuality']\n",
        "    return image_quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3Hpa40LjMGL"
      },
      "outputs": [],
      "source": [
        "def quality_percentage_test(model):\n",
        "  good_4ch=[]\n",
        "  medium_4ch=[]\n",
        "  poor_4ch=[]\n",
        "  good_2ch=[]\n",
        "  medium_2ch=[]\n",
        "  poor_2ch=[]\n",
        "  frame_4ch_counter=0\n",
        "  frame_2ch_counter=0\n",
        "  for patient in range(1,51):\n",
        "      image_4ch_file=fetch_test_file(patient=patient,option='4CH')\n",
        "      image_2ch_file=fetch_test_file(patient=patient,option='2CH')\n",
        "      image_4ch=get_array(image_4ch_file)\n",
        "      image_2ch=get_array(image_2ch_file)\n",
        "      true_quality_4ch=fetch_test_image_quality(patient,option='4CH')\n",
        "      true_quality_2ch=fetch_test_image_quality(patient,option='2CH')\n",
        "      for j in range(image_4ch.shape[0]):\n",
        "             rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             tensor_image=preprocessing(rgb_image)\n",
        "             pred_label=model(tensor_image)\n",
        "             if pred_label == 1 :\n",
        "               frame_4ch_counter+=1\n",
        "               if true_quality_4ch == 'Good':\n",
        "                   good_4ch.append(0)\n",
        "               elif true_quality_4ch == 'Medium':\n",
        "                   medium_4ch.append(0)\n",
        "               else :\n",
        "                   poor_4ch.append(0)\n",
        "      for j in range(image_2ch.shape[0]):\n",
        "             rgb_image = cv2.cvtColor(image_2ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             tensor_image=preprocessing(rgb_image)\n",
        "             pred_label=model.predict(tensor_image)\n",
        "             if pred_label == 0 :\n",
        "               frame_2ch_counter+=1\n",
        "               if true_quality_2ch == 'Good':\n",
        "                   good_2ch.append(0)\n",
        "               elif true_quality_2ch == 'Medium':\n",
        "                   medium_2ch.append(0)\n",
        "               else :\n",
        "                   poor_2ch.append(0)\n",
        "  print(f\"Good 4ch lost are {len(good_4ch)} and precentage is {len(good_4ch)/frame_4ch_counter}\")\n",
        "  print(f\"Medium 4ch lost are {len(medium_4ch)} and precentage is {len(medium_4ch)/frame_4ch_counter}\")\n",
        "  print(f\"Poor 4ch lost are {len(poor_4ch)} and precentage is {len(poor_4ch)/frame_4ch_counter}\")\n",
        "  print(f\"Good 2ch lost are {len(good_2ch)} and precentage is {len(good_2ch)/frame_2ch_counter}\")\n",
        "  print(f\"Medium 2ch lost are {len(medium_2ch)} and precentage is {len(medium_2ch)/frame_2ch_counter}\")\n",
        "  print(f\"Poor 2ch lost are {len(poor_2ch)} and precentage is {len(poor_2ch)/frame_2ch_counter}\")\n",
        "  return good_4ch,medium_4ch,poor_4ch,good_2ch,medium_2ch,poor_2ch,frame_4ch_counter,frame_2ch_counter\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_E3KAexQUGf"
      },
      "outputs": [],
      "source": [
        "def quality_percentage_test_hog(model):\n",
        "  good_4ch=[]\n",
        "  medium_4ch=[]\n",
        "  poor_4ch=[]\n",
        "  good_2ch=[]\n",
        "  medium_2ch=[]\n",
        "  poor_2ch=[]\n",
        "  frame_4ch_counter=0\n",
        "  frame_2ch_counter=0\n",
        "  for patient in range(1,51):\n",
        "      image_4ch_file=fetch_test_file(patient=patient,option='4CH')\n",
        "      image_2ch_file=fetch_test_file(patient=patient,option='2CH')\n",
        "      image_4ch=get_array(image_4ch_file)\n",
        "      image_2ch=get_array(image_2ch_file)\n",
        "      true_quality_4ch=fetch_test_image_quality(patient,option='4CH')\n",
        "      true_quality_2ch=fetch_test_image_quality(patient,option='2CH')\n",
        "      for j in range(image_4ch.shape[0]):\n",
        "             #rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             rgb_image=image_4ch[j,:,:]\n",
        "             tensor_image=preprocessing(rgb_image).numpy()\n",
        "             pred_label=model.predict(tensor_image)\n",
        "             if pred_label == 1 :\n",
        "               frame_4ch_counter+=1\n",
        "               if true_quality_4ch == 'Good':\n",
        "                   good_4ch.append(0)\n",
        "               elif true_quality_4ch == 'Medium':\n",
        "                   medium_4ch.append(0)\n",
        "               else :\n",
        "                   poor_4ch.append(0)\n",
        "      for j in range(image_2ch.shape[0]):\n",
        "             #rgb_image = cv2.cvtColor(image_4ch[j,:,:],cv2.COLOR_GRAY2RGB)\n",
        "             rgb_image=image_4ch[j,:,:]\n",
        "             tensor_image=preprocessing(rgb_image).numpy()\n",
        "             pred_label=model.predict(tensor_image)\n",
        "             if pred_label == 0 :\n",
        "               frame_2ch_counter+=1\n",
        "               if true_quality_2ch == 'Good':\n",
        "                   good_2ch.append(0)\n",
        "               elif true_quality_2ch == 'Medium':\n",
        "                   medium_2ch.append(0)\n",
        "               else :\n",
        "                   poor_2ch.append(0)\n",
        "  print(f\"Good 4ch lost are {len(good_4ch)} and precentage is {len(good_4ch)/frame_4ch_counter}\")\n",
        "  print(f\"Medium 4ch lost are {len(medium_4ch)} and precentage is {len(medium_4ch)/frame_4ch_counter}\")\n",
        "  print(f\"Poor 4ch lost are {len(poor_4ch)} and precentage is {len(poor_4ch)/frame_4ch_counter}\")\n",
        "  print(f\"Good 2ch lost are {len(good_2ch)} and precentage is {len(good_2ch)/frame_2ch_counter}\")\n",
        "  print(f\"Medium 2ch lost are {len(medium_2ch)} and precentage is {len(medium_2ch)/frame_2ch_counter}\")\n",
        "  print(f\"Poor 2ch lost are {len(poor_2ch)} and precentage is {len(poor_2ch)/frame_2ch_counter}\")\n",
        "  return good_4ch,medium_4ch,poor_4ch,good_2ch,medium_2ch,poor_2ch,frame_4ch_counter,frame_2ch_counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jvVjb3oqZ9C_"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "image_file_path=\"drive/MyDrive/training_dataset/training/patient0001/patient0001_4CH_sequence.mhd\"\n",
        "img_4=[]\n",
        "img = sitk.ReadImage(image_file_path)\n",
        "img_1=sitk.GetArrayFromImage(img)\n",
        "img_4.append(img_1[0,:,:])\n",
        "hog_feature,hog_image = hog(img_1[0,:,:],transform_sqrt=False,\n",
        "                                        orientations=9,pixels_per_cell=(8,8),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "img_4.append(hog_image)\n",
        "fig = plt.figure(figsize=(16., 16.))\n",
        "grid = ImageGrid(fig, 111,\n",
        "                 nrows_ncols=(1,2),\n",
        "                 axes_pad=0.1,\n",
        "                 )\n",
        "for ax, im in zip(grid,img_4):\n",
        "    ax.imshow(im,cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsDmHNFQnqWg"
      },
      "outputs": [],
      "source": [
        "tmed=pd.read_csv('drive/MyDrive/labeled/labels_per_image.csv')\n",
        "tmed.drop(\"diagnosis_label\",axis=1,inplace=True)\n",
        "tmed.drop(tmed[tmed['view_label'] == \"PLAX\"].index,inplace=True)\n",
        "tmed.drop(tmed[tmed['view_label'] == \"PSAX\"].index,inplace=True)\n",
        "tmed.drop(tmed[tmed['view_label'] == \"A4CorA2CorOther\"].index,inplace=True)\n",
        "print(tmed[\"view_label\"].value_counts())\n",
        "print(tmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95EbM0_FkZzy"
      },
      "outputs": [],
      "source": [
        "q='3131s2_4.png'\n",
        "view_label=fetch_tmed_image_quality(tmed,q)\n",
        "view_label=get_tmed_view_label(view_label)\n",
        "print(view_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbW8yx8fgtTn"
      },
      "outputs": [],
      "source": [
        "def create_tmed_sklearn_set(tmed):\n",
        "    files = os.listdir('drive/MyDrive/labeled')\n",
        "    dataset=list()\n",
        "    dataset_labels=list()\n",
        "    for file in files:\n",
        "      query_key=get_query_key(tmed,file)\n",
        "      if query_key == 0 :\n",
        "        continue\n",
        "      image=get_tmed_array(query_key)\n",
        "      view_label=fetch_tmed_image_quality(tmed,query_key)\n",
        "      label=get_tmed_view_label(view_label)\n",
        "      tensor_image=preprocessing(image).numpy()\n",
        "      hog_feature,hog_image = hog(image,transform_sqrt=False,\n",
        "                                        orientations=9,pixels_per_cell=(8,8),cells_per_block=(2, 2),\n",
        "                                        visualize=True,feature_vector=True)\n",
        "      dataset.append(hog_feature)\n",
        "      dataset_labels.append(label)\n",
        "    dataset=np.array(dataset)\n",
        "    dataset_labels=np.array(dataset_labels)\n",
        "    return dataset,dataset_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47-FMcA-X4ZH"
      },
      "outputs": [],
      "source": [
        "X_test,Y_test=create_tmed_sklearn_set(tmed)\n",
        "print(X_test.shape)\n",
        "print(Y_test[Y_test == 0].shape)\n",
        "print(Y_test[Y_test == 1].shape)\n",
        "filename='drive/MyDrive/training_dataset/logistic_classifier_450_hog.sav'\n",
        "model=load_sklearn_model(filename)\n",
        "sklearn_performance_metrics(model,X_test,Y_test,binary= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhPHjaI-C4U5"
      },
      "outputs": [],
      "source": [
        "def create_tmed_set(tmed):\n",
        "    files = os.listdir('drive/MyDrive/labeled')\n",
        "    dataset=list()\n",
        "    dataset_labels=list()\n",
        "    for file in files:\n",
        "      query_key=get_query_key(tmed,file)\n",
        "      if query_key == 0 :\n",
        "        continue\n",
        "      image=get_tmed_array(query_key)\n",
        "      view_label=fetch_tmed_image_quality(tmed,query_key)\n",
        "      label=get_tmed_view_label(view_label)\n",
        "      rgb_image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
        "      tensor_image=preprocessing(rgb_image)\n",
        "      dataset.append(tensor_image)\n",
        "      dataset_labels.append(label)\n",
        "    return dataset,dataset_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1xNQa2k3DGlA"
      },
      "outputs": [],
      "source": [
        "device=get_default_device()\n",
        "images,labels=create_tmed_set(tmed)\n",
        "test_ds=MyDataset(images=images,labels=labels)\n",
        "batch_size=16\n",
        "test_tmed = DataLoader(test_ds, batch_size*2, num_workers=2, pin_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JipIxoQvDHDW"
      },
      "outputs": [],
      "source": [
        "filename='drive/MyDrive/training_dataset/resnet152_450_0.001_best.pt'\n",
        "model=load_model_resnet152(filename)\n",
        "print_perfomance_metrics(model,test_tmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsDtCEqHknlK"
      },
      "outputs": [],
      "source": [
        "def get_query_key(tmed,file):\n",
        "    if tmed[tmed['query_key'] == file].empty :\n",
        "      return 0\n",
        "    else :\n",
        "      return tmed[tmed['query_key'] == file].values[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgF8fU52he0I"
      },
      "outputs": [],
      "source": [
        "def get_tmed_view_label(view_label):\n",
        "  if view_label == 'A4C':\n",
        "     label=0\n",
        "  else :\n",
        "     label=1\n",
        "  return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzPMW7a7hfQV"
      },
      "outputs": [],
      "source": [
        "def get_tmed_array(image_file):\n",
        "  path_to_file='drive/MyDrive/labeled/'\n",
        "  im_frame = Image.open(path_to_file + image_file)\n",
        "  im_frame=brighten_image(im_frame)\n",
        "  array=np.array(im_frame)\n",
        "  return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abQIFfB0iU68"
      },
      "outputs": [],
      "source": [
        "def fetch_tmed_image_quality(tmed,file):\n",
        "    label=tmed[tmed['query_key'] == file].values[0][1]\n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nXzxHHvaXLWV"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageEnhance\n",
        "def brighten_image(image):\n",
        "    factor = 2\n",
        "    enhancer = ImageEnhance.Brightness(image)\n",
        "    im_output = enhancer.enhance(factor)\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    im_output = enhancer.enhance(factor)\n",
        "    return im_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05XZUJZgk1r8"
      },
      "outputs": [],
      "source": [
        "device=get_default_device()\n",
        "images,labels=create_tensor_set_quality(tmed)\n",
        "test_tmed_ds=MyDataset(images=images,labels=labels)\n",
        "batch_size=32\n",
        "test_tmed_loader = DataLoader(test_tmed_ds, batch_size*2, num_workers=2, pin_memory=False)\n",
        "#test_dl = DeviceDataLoader(test_tmed_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VQUn-YjlOrj"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "path_to_file='drive/MyDrive/labeled/'\n",
        "file='235s1_1.png'\n",
        "im_frame = get_tmed_array(file)\n",
        "array=np.array(im_frame)\n",
        "print(array.shape)\n",
        "#image_resized = resize(array, (224,224),\n",
        "                       #anti_aliasing=True)\n",
        "plt.imshow(array,cmap=\"gray\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPB_dPjau6A_"
      },
      "outputs": [],
      "source": [
        "files = os.listdir('drive/MyDrive/labeled')\n",
        "for file in files:\n",
        "    if not tmed[tmed['query_key'] == file].empty :\n",
        "         print(tmed[tmed['query_key'] == file].values[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYMIT_MOcHC9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "flag_A4C=0\n",
        "flag_A2C=0\n",
        "flag_PLAX=0\n",
        "flag_PSAX=0\n",
        "images=[]\n",
        "label=[]\n",
        "files = os.listdir('drive/MyDrive/labeled')\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "    query_key=get_query_key(tmed,file)\n",
        "    if query_key == 0 :\n",
        "        continue\n",
        "    view_label=fetch_tmed_image_quality(tmed,query_key)\n",
        "    if view_label == 'A4C' and flag_A4C == 0 :\n",
        "        image=get_tmed_array(query_key)\n",
        "        images.append(image)\n",
        "        label.append(view_label)\n",
        "        flag_A4C=1\n",
        "    if view_label == 'A2C' and flag_A2C == 0 :\n",
        "        image=get_tmed_array(query_key)\n",
        "        images.append(image)\n",
        "        label.append(view_label)\n",
        "        flag_A2C=1\n",
        "    if view_label == 'PLAX' and flag_PLAX == 0 :\n",
        "        image=get_tmed_array(query_key)\n",
        "        images.append(image)\n",
        "        label.append(view_label)\n",
        "        flag_PLAX=1\n",
        "    if view_label == 'PSAX' and flag_PSAX == 0 :\n",
        "        image=get_tmed_array(query_key)\n",
        "        images.append(image)\n",
        "        label.append(view_label)\n",
        "        flag_PSAX=1\n",
        "    if flag_A2C+flag_A4C+ flag_PLAX+flag_PSAX == 4:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0p_dFXrd84h"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "fig = plt.figure(figsize=(16., 16.))\n",
        "grid = ImageGrid(fig, 111,\n",
        "                 nrows_ncols=(1,4),\n",
        "                 axes_pad=0.15,\n",
        "                 )\n",
        "for ax, im in zip(grid,images):\n",
        "    ax.imshow(im,cmap=\"gray\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}